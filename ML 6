import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Step 1: Read the Dataset
data = pd.read_csv('sales_data_sample.csv')  # Adjust the filename to the actual dataset file

# Step 2: Preprocess the Data
# Depending on the dataset, clean and preprocess it as needed.
# You may need to select specific features and transform them.

# Step 3: Determine the Number of Clusters (Elbow Method)
wcss = []  # Within-cluster sum of squares
max_k = 10  # Maximum number of clusters to test (can adjust)
for k in range(1, max_k + 1):
    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(data)  # Assuming 'data' contains the relevant features
    wcss.append(kmeans.inertia_)

# Plot the Elbow Method
plt.figure(figsize=(8, 6))
plt.plot(range(1, max_k + 1), wcss, marker='o', linestyle='--')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('WCSS')
plt.show()

# Determine the optimal k value based on the elbow in the plot

# Step 4: Implement K-Means Clustering
optimal_k = 3  # Replace with the determined optimal k value
kmeans = KMeans(n_clusters=optimal_k, init='k-means++', max_iter=300, n_init=10, random_state=0)
kmeans.fit(data)  # Assuming 'data' contains the relevant features

# Step 5: Visualize the Clusters
pca = PCA(n_components=2)
data_2d = pca.fit_transform(data)
cluster_labels = kmeans.predict(data)

plt.figure(figsize=(8, 6))
plt.scatter(data_2d[:, 0], data_2d[:, 1], c=cluster_labels, cmap='rainbow')
plt.title('K-Means Clustering Results')
plt.show()
